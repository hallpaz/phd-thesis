\chapter{Introduction}

Nice introductory text here identifying the gaps and the research question.



Machine learning has been initially introduced in Computer Vision as a tool for solving analysis tasks such object detection [CITE], instance segmentation [CITE], pose estimation [CITE] and other scene understanding tasks [CITE]. 

Later on, generative models such as Variational Auto-encoders [CITE] and Generative Adversarial Networks (GANs) [CITE] have opened new possibilities in the realm of learning to generate a family of objects. While most of the works have concentrated into image generation [CITE], there have been exploration in the direction of other media objects [CITE]


As these two use cases became more "stable", the field kept advancing towards non-euclidean domains. How to apply machine learning techiniques, more specifically, deep learning, to solve problems in Computer Graphics?

Note that audio, image and videos have a natural representation in euclidean domains, as their digital representations are encoded as lattices, samples with regularity in space and time. When dealing with 3D models, there are many possible representations available such as point clouds, polygonal meshes, multiview images or implicit surfaces.

Many works have addressed each of these representations. For instance [CITE works for each kind]... At this point, other tasks such as geometry reconstruction and appearance estimation started to be better addressed. Still, most of these works could be either classified as analysis - how to classify an object based on a point cloud - or generative models based: after training on a dataset, given an image as a prior, generate the corresponding geometry.

In this context, using neural networks to represent media objects such as audio, image, video or 3D models have attracted attention of the community as it is a compact and continuous representation. 


\section{Motivation and Vision}

Lore ipsum.

\section{Research Questions}

Lore ipsum.


\section{Contributions}

In summary the contributions of this dissertation are:

\begin{itemize}
    \item TODO: A characterization of representational neural networks as an unified view to implicit models and implicit neural fields, distinguishing them from analysis networks and generative networks
    \item An architecture of neural networks to encode media objects in multiresolution using an implicit model representation.
    \item A study of sinusoidal neural networks initialization for multiresolution and periodic signal representation.
    \item A flexible framework for training multi-stage neural networks using different types of multiresolution data.
    \item We demonstrate how our architecture can be applied to multiresolution image representation and continuous interpolation in space and scale to solve anti-aliasing.
    \item We demonstrate how to periodic sinusoidal neural networks to represent periodic textures and we develop a techinique based on Poisson Equation to create seamless material textures.
    \item We demonstrate how to use our architecture for rendering of textured objects and panoramic scenes. [TODO: We also show how to use Neural Rendering to learn an equirectangular representation from multiple sampled images of a scene.]
\end{itemize}