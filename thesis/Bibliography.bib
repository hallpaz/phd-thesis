% Books
@book{daubechies92,
author = {Daubechies, Ingrid},
title = {Ten lectures on wavelets},
year = {1992},
isbn = {0898712742},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA}
}

@book{wenger2013isosurfaces,
  author    = {Raphael Wenger},
  title     = {Isosurfaces: Geometry, Topology, and Algorithms},
  edition   = {1st},
  publisher = {A K Peters/CRC Press},
  year      = {2013},
  doi       = {10.1201/b15025}
}


% Articles

@article{Shannon1949, 
  doi = {10.1109/jrproc.1949.232969}, 
  url = {https://doi.org/10.1109/jrproc.1949.232969}, 
  year  = {1949}, 
  month = {jan}, 
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})}, 
  volume = {37}, 
  number = {1}, 
  pages = {10--21}, 
  author = {C.E. Shannon}, 
  title = {Communication in the Presence of Noise}, 
  journal = {Proceedings of the {IRE}} 
}

@ARTICLE{zhangWavelet92,
  author={Zhang, Q. and Benveniste, A.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Wavelet networks}, 
  year={1992},
  volume={3},
  number={6},
  pages={889-898},
  keywords={Neural networks;Feedforward neural networks;Backpropagation algorithms;Discrete transforms;Continuous wavelet transforms;Wavelet transforms;Nonlinear systems;Power system modeling;Convergence},
  doi={10.1109/72.165591}
}

@ARTICLE{bruna2013,
  author={Bruna, Joan and Mallat, Stephane},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Invariant Scattering Convolution Networks}, 
  year={2013},
  volume={35},
  number={8},
  pages={1872-1886},
  keywords={Scattering;Convolution;Fourier transforms;Wavelet coefficients;Computer architecture;Classification;convolution networks;deformations;invariants;wavelets},
  doi={10.1109/TPAMI.2012.230}
}

@article{sppHe2015,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition},
year = {2015},
issue_date = {Sept. 2015},
publisher = {IEEE Computer Society},
address = {USA},
volume = {37},
number = {9},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2015.2389824},
doi = {10.1109/TPAMI.2015.2389824},
abstract = {Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224<inline-formula><tex-math>$times$ </tex-math><alternatives><inline-graphic xlink:type="simple" xlink:href="he-ieq1-2389824.gif"/></alternatives></inline-formula>224) input image. This requirement is “artificial” and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, “spatial pyramid pooling”, to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102 <inline-formula><tex-math>$times$</tex-math><alternatives><inline-graphic xlink:type="simple" xlink:href="he-ieq2-2389824.gif"/> </alternatives></inline-formula> faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = sep,
pages = {1904–1916},
numpages = {13}
}

@inproceedings{YuKoltun2016,
	author    = {Fisher Yu and Vladlen Koltun},
	title     = {Multi-Scale Context Aggregation by Dilated Convolutions},
	booktitle = {ICLR},
	year      = {2016},
}


@inproceedings{goodfellow2014generative, 
  title={Generative adversarial nets}, 
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems}, 
  pages={2672--2680}, 
  year={2014} 
}

@article{ho2020denoising,
  title={Denoising Diffusion Probabilistic Models},
  author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
  year={2020},
  journal={arXiv preprint arxiv:2006.11239}
}

@article{gomes1995,
  title={Abstraction paradigms for computer graphics},
  author={Gomes, J. and Velho, L},
  year={1995},
  journal={The Visual Computer 11, 227-239},
  url = {https://doi.org/10.1007/BF01901041}
}

@article{variantTextures,
author = {Zhang, Jingdan and Zhou, Kun and Velho, Luiz and Guo, Baining and Shum, Heung-Yeung},
title = {Synthesis of progressively-variant textures on arbitrary surfaces},
year = {2003},
issue_date = {July 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/882262.882266},
doi = {10.1145/882262.882266},
abstract = {We present an approach for decorating surfaces with progressively-variant textures. Unlike a homogeneous texture, a progressively-variant texture can model local texture variations, including the scale, orientation, color, and shape variations of texture elements. We describe techniques for modeling progressively-variant textures in 2D as well as for synthesizing them over surfaces. For 2D texture modeling, our feature-based warping technique allows the user to control the shape variations of texture elements, making it possible to capture complex texture variations such as those seen in animal coat patterns. In addition, our feature-based blending technique can create a smooth transition between two given homogeneous textures, with progressive changes of both shapes and colors of texture elements. For synthesizing textures over surfaces, the biggest challenge is that the synthesized texture elements tend to break apart as they progressively vary. To address this issue, we propose an algorithm based on texton masks, which mark most prominent texture elements in the 2D texture sample. By leveraging the power of texton masks, our algorithm can maintain the integrity of the synthesized texture elements on the target surface.},
journal = {ACM Trans. Graph.},
month = jul,
pages = {295-302},
numpages = {8},
keywords = {surfaces, texture mapping, texture synthesis}
}

@article{gomesGraphical1996,
  title={Graphical objects},
  author={Gomes, J. and Costa, B. and Darsa, L. and Velho, L.},
  year={1996},
  journal={The Visual Computer 12, 269-282},
  url = {https://doi.org/10.1007/BF01782289}
}

@inproceedings{bacon2021,
author = {D. Lindell and D. Van Veen and J. Park and G. Wetzstein},
title = {{BACON}: Band-limited coordinate networks for multiscale scene representation},
booktitle = {Proceedings of CVPR},
year={2022}
}

@article{BAJAJ-2000,
title = {Compression-Based 3D Texture Mapping for Real-Time Rendering},
journal = {Graphical Models},
volume = {62},
number = {6},
pages = {391-410},
year = {2000},
issn = {1524-0703},
doi = {https://doi.org/10.1006/gmod.2000.0532},
url = {https://www.sciencedirect.com/science/article/pii/S1524070300905320},
author = {Chandrajit Bajaj and Insung Ihm and Sanghun Park},
abstract = {While 2D texture mapping is one of the most effective of the rendering techniques that make 3D objects appear visually interesting, it often suffers from visual artifacts produced when 2D image patterns are wrapped onto the surfaces of objects with arbitrary shapes. On the other hand, 3D texture mapping generates highly natural visual effects in which objects appear carved from lumps of materials rather than laminated with thin sheets as in 2D texture mapping. Storing 3D texture images in a table for fast mapping computations, instead of evaluating procedures on the fly, however, has been considered impractical due to the extremely high memory requirement. In this paper, we present a new effective method for 3D texture mapping designed for real-time rendering of polygonal models. Our scheme attempts to resolve the potential texture memory problem by compressing 3D textures using a wavelet-based encoding method. The experimental results on various nontrivial 3D textures and polygonal models show that high compression rates are achieved with few visual artifacts in the rendered images and a small impact on rendering time. The simplicity of our compression-based scheme will make it easy to implement practical 3D texture mapping in software/hardware rendering systems including real-time 3D graphics APIs such as OpenGL and Direct3D.}
}

@book{ipcgVelho2014,
  author = {Velho, Luiz and Frery, Alejandro C. and Gomes, Jonas},
  title = {Image Processing for Computer Graphics and Vision},
  year = {2014},
  isbn = {1447160150},
  publisher = {Springer Publishing Company, Incorporated},
  edition = {2nd},
  abstract = {Image processing is concerned with the analysis and manipulation of images by computer. Providing a thorough treatment of image processing with an emphasis on those aspects most used in computer graphics, the authors concentrate on describing and analyzing the underlying concepts rather than on presenting algorithms or pseudocode. As befits a modern introduction to this topic, a good balance is struck between discussing the underlying mathematics and the main topics: signal processing, data discretization, the theory of colour and different colour systems, operations in images, dithering and half-toning, warping and morphing and image processing. This second edition reflects recent trends in science andtechnology that exploit image processing in computer graphics and vision applications. Stochastic image models and statistical methods for image processing are covered as are: A modern approach and new developments in the area, Probability theory for image processing, Applications in image analysis and computer vision.}
}

@book{GomesVelho2015FromFA,
  title={From Fourier Analysis to Wavelets},
  author={Jonas Gomes and Luiz Velho},
  year={2015},
  publisher = {Springer Cham},
  url={https://api.semanticscholar.org/CorpusID:115231936},
  doi = {https://doi.org/10.1007/978-3-319-22075-8}
}

@article{bhaskaran1997image,
  title={Image and video compression standards: algorithms and architectures},
  author={Bhaskaran, Vasudev and Konstantinides, Konstantinos},
  year={1997},
  publisher={Springer Science \& Business Media}
}

@article{hypertexture,
author = {Perlin, K. and Hoffert, E. M.},
title = {Hypertexture},
year = {1989},
issue_date = {July 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/74334.74359},
doi = {10.1145/74334.74359},
abstract = {We model phenomena intermediate between shape and texture by using space-filling applicative functions to modulate density. The model is essentially an extension of procedural solid texture synthesis, but evaluated throughout a volumetric region instead of only at surfaces.We have been able to obtain visually realistic representations of such shape+texture (hypertexture) phenomena as hair, fur, fire, glass, fluid flow and erosion effects. We show how this is done, first by describing a set of base level functions to provide basic texture and control capability, then by combining these to synthesize various phenomena.Hypertexture exists within an intermediate region between object and not-object. We introduce a notion of generalized boolean shape operators to combine shapes having such a region.Rendering is accomplished by ray marching from the eye point through the volume to accumulate opacity along each ray. We have implemented our hypertexture rendering algorithms on a traditional serial computer, a distributed network of computers and a coarse-grain MIMD computer. Extensions to the rendering technique incorporating refraction and reflection effects are discussed.},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {253–262},
numpages = {10}
}


@article{HORNIK1989359,
title = {Multilayer feedforward networks are universal approximators},
journal = {Neural Networks},
volume = {2},
number = {5},
pages = {359-366},
year = {1989},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(89)90020-8},
url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
author = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
keywords = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.}
}

@article{cybenko89,
  abstract = {{In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function of n real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.}},
  added-at = {2012-03-02T03:39:18.000+0100},
  author = {Cybenko, G.},
  biburl = {https://www.bibsonomy.org/bibtex/2be85c56ae384216b2e35bdf79b7fb477/baby9992006},
  citeulike-article-id = {3561150},
  citeulike-linkout-0 = {http://dx.doi.org/10.1007/BF02551274},
  citeulike-linkout-1 = {http://www.springerlink.com/content/n873j15736072427},
  day = 1,
  doi = {10.1007/BF02551274},
  interhash = {96aecb02daa11041489259a8edb54070},
  intrahash = {be85c56ae384216b2e35bdf79b7fb477},
  issn = {0932-4194},
  journal = {Mathematics of Control, Signals, and Systems (MCSS)},
  keywords = {approximation, control, duckling, free, lunch, no, theorem, theory, ugly, universal},
  month = dec,
  number = 4,
  pages = {303--314},
  posted-at = {2012-02-28 13:17:08},
  priority = {2},
  publisher = {Springer London},
  timestamp = {2012-03-02T03:39:20.000+0100},
  title = {{Approximation by superpositions of a sigmoidal function}},
  url = {http://dx.doi.org/10.1007/BF02551274},
  volume = 2,
  year = 1989
}


@article{blinn76,
author = {Blinn, James F. and Newell, Martin E.},
title = {Texture and Reflection in Computer Generated Images},
year = {1976},
issue_date = {Oct. 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/360349.360353},
doi = {10.1145/360349.360353},
journal = {Commun. ACM},
month = {oct},
pages = {542–547},
numpages = {6} 
}

@book{bracewell1986fourier,
  title={The Fourier transform and its applications},
  author={Bracewell, Ronald Newbold and Bracewell, Ronald N},
  volume={31999},
  year={1986},
  publisher={McGraw-Hill New York}
}

@incollection{burt1987laplacian,
  title={The Laplacian pyramid as a compact image code},
  author={Burt, Peter J and Adelson, Edward H},
  booktitle={Readings in computer vision},
  pages={671--679},
  year={1987},
  publisher={Elsevier}
}

@ARTICLE{dct-og,
  author={Ahmed, N. and Natarajan, T. and Rao, K.R.},
  journal={IEEE Transactions on Computers}, 
  title={Discrete Cosine Transform}, 
  year={1974},
  volume={C-23},
  number={1},
  pages={90-93},
  doi={10.1109/T-C.1974.223784}}


@inproceedings{park2019deepsdf,
  title={Deepsdf: Learning continuous signed distance functions for shape representation},
  author={Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={165--174},
  year={2019}
}

@inproceedings{occupancy_networks,
  title = {Occupancy Networks: Learning 3D Reconstruction in Function Space},
  author = {Mescheder, Lars and Oechsle, Michael and Niemeyer, Michael and Nowozin, Sebastian and Geiger, Andreas},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019},
  doi = {}
}

@inproceedings{2020nerf,
 title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
 author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
 year={2020},
 booktitle={ECCV},
}

@article{barron2022mipnerf360,
    title={Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields},
    author={Jonathan T. Barron and Ben Mildenhall and 
            Dor Verbin and Pratul P. Srinivasan and Peter Hedman},
    journal={CVPR},
    year={2022}
}



@inproceedings{deeptile,
author = {Toulatzis, Vasilis and Fudos, Ioannis},
title = {Deep Tiling: Texture Tile Synthesis Using a Constant Space Deep Learning Approach},
year = {2021},
isbn = {978-3-030-90438-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90439-5_33},
doi = {10.1007/978-3-030-90439-5_33},
abstract = {Texturing is a fundamental process in computer graphics. Texture is leveraged to enhance the visualization outcome for a 3D scene. In many cases a texture image cannot cover a large 3D model surface because of its small resolution. Conventional techniques like repeating, mirroring or clamping to edge do not yield visually acceptable results. Deep learning based texture synthesis has proven to be very effective in such cases. All deep texture synthesis methods that attempt to create larger resolution textures are limited in terms of GPU memory resources. In this paper, we propose a novel approach to example-based texture synthesis by using a robust deep learning process for creating tiles of arbitrary resolutions that resemble the structural components of an input texture. In this manner, our method is firstly much less memory limited owing to the fact that a new texture tile of small size is synthesized and merged with the existing texture and secondly can easily produce missing parts of a large texture.},
booktitle = {Advances in Visual Computing: 16th International Symposium, ISVC 2021, Virtual Event, October 4-6, 2021, Proceedings, Part I},
pages = {414–426},
numpages = {13},
keywords = {Deep learning, Texture synthesis}
}

@article{dorsey-2004,
author = {Jagnow, Robert and Dorsey, Julie and Rushmeier, Holly},
title = {Stereological Techniques for Solid Textures},
year = {2004},
issue_date = {August 2004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/1015706.1015724},
doi = {10.1145/1015706.1015724},
abstract = {We describe the use of traditional stereological methods to synthesize 3D solid textures from 2D images of existing materials. We first illustrate our approach for aggregate materials of spherical particles, and then extend the technique to apply to particles of arbitrary shapes. We demonstrate the effectiveness of the approach with side-by-side comparisons of a real material and a synthetic model with its appearance parameters derived from its physical counterpart. Unlike ad hoc methods for texture synthesis, stereology provides a disciplined, systematic basis for predicting material structure with well-defined assumptions.},
journal = {ACM Trans. Graph.},
month = {aug},
pages = {329–335},
numpages = {7},
keywords = {procedural textures, solid textures, texture synthesis, volumetric textures, spatial sampling theory, stereology}
}


@INPROCEEDINGS{efros99,
  author={Efros, A.A. and Leung, T.K.},
  booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision}, 
  title={Texture synthesis by non-parametric sampling}, 
  year={1999},
  volume={2},
  number={},
  pages={1033-1038 vol.2},
  doi={10.1109/ICCV.1999.790383}
}

@article{etal-2010,
author = {Lagae, A. and Lefebvre, S. and Cook, R. and DeRose, T. and Drettakis, G. and Ebert, D.S. and Lewis, J.P. and Perlin, K. and Zwicker, M.},
title = {A Survey of Procedural Noise Functions},
journal = {Computer Graphics Forum},
volume = {29},
number = {8},
pages = {2579-2600},
keywords = {procedural noise function, noise, stochastic process, procedural, Perlin noise, wavelet noise, anisotropic noise, sparse convolution noise, Gabor noise, spot noise, surface noise, solid noise, anti-aliasing, filtering, stochastic modelling, procedural texture, procedural modelling, solid texture, texture synthesis, spectral analysis, power spectrum estimation, I.3.3 Computer Graphics: Picture/Image Generation—I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism-Colour, shading, shadowing, and texture},
doi = {https://doi.org/10.1111/j.1467-8659.2010.01827.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2010.01827.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2010.01827.x},
abstract = {Abstract Procedural noise functions are widely used in computer graphics, from off-line rendering in movie production to interactive video games. The ability to add complex and intricate details at low memory and authoring cost is one of its main attractions. This survey is motivated by the inherent importance of noise in graphics, the widespread use of noise in industry and the fact that many recent research developments justify the need for an up-to-date survey. Our goal is to provide both a valuable entry point into the field of procedural noise functions, as well as a comprehensive view of the field to the informed reader. In this report, we cover procedural noise functions in all their aspects. We outline recent advances in research on this topic, discussing and comparing recent and well-established methods. We first formally define procedural noise functions based on stochastic processes and then classify and review existing procedural noise functions. We discuss how procedural noise functions are used for modelling and how they are applied to surfaces. We then introduce analysis tools and apply them to evaluate and compare the major approaches to noise generation. We finally identify several directions for future work.},
year = {2010}
}

@inproceedings{fathony2020multiplicative,
  title={Multiplicative filter networks},
  author={Fathony, Rizal and Sahu, Anit Kumar and Willmott, Devin and Kolter, J Zico},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{Gutierrez-2019,
	year = 2019,
	month = {nov},
	publisher = {Wiley},
	volume = {39},
	number = {1},
	pages = {511--530},
	author = {J. Gutierrez and J. Rabin and B. Galerne and T. Hurtut},
	title = {On Demand Solid Texture Synthesis Using Deep 3D Networks},
abstract = {This paper describes a novel approach for on demand volumetric texture synthesis based on a deep learning framework that allows for the generation of high quality 3D data at interactive rates. Based on a few example images of textures, a generative network is trained to synthesize coherent portions of solid textures of arbitrary sizes that reproduce the visual characteristics of the examples along some directions. To cope with memory limitations and computation complexity that are inherent to both high resolution and 3D processing on the GPU, only 2D textures referred to as “slices” are generated during the training stage. These synthetic textures are compared to exemplar images via a perceptual loss function based on a pre-trained deep network. The proposed network is very light (less than 100k parameters), therefore it only requires sustainable training (i.e. few hours) and is capable of very fast generation (around a second for 2563 voxels) on a single GPU. Integrated with a spatially seeded PRNG the proposed generator network directly returns an RGB value given a set of 3D coordinates. The synthesized volumes have good visual results that are at least equivalent to the state-of-the-art patch based approaches. They are naturally seamlessly tileable and can be fully generated in parallel.},
	journal = {Computer Graphics Forum}
}



@inproceedings{haeberli90,
author = {Haeberli, Paul},
title = {Paint by Numbers: Abstract Image Representations},
year = {1990},
isbn = {0897913442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/97879.97902},
doi = {10.1145/97879.97902},
abstract = {Computer graphics research has concentrated on creating photo-realistic images of synthetic objects. These images communicate surface shading and curvature, as well as the depth relationships of objects in a scene. These renderings are traditionally represented by a rectangular array of pixels that tile the image plane.As an alternative to photo-realism, it is possible to create abstract images using an ordered collection of brush strokes. These abstract images filter and refine visual information before it is presented to the viewer. By controlling the color, shape, size, and orientation of individual brush strokes, impressionistic paintings of computer generated or photographic images can easily be created.},
booktitle = {Proceedings of the 17th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {207–214},
numpages = {8},
location = {Dallas, TX, USA},
series = {SIGGRAPH '90}
}

@book{marr82,
  added-at = {2012-10-25T15:58:41.000+0200},
  address = {New York, NY, USA},
  author = {Marr, David},
  biburl = {https://www.bibsonomy.org/bibtex/2771360e49193a390e85f280dd207de20/daill},
  description = {Vision},
  interhash = {31060780234ce2036de55d261cc63a61},
  intrahash = {771360e49193a390e85f280dd207de20},
  isbn = {0716715678},
  keywords = {computer vision},
  publisher = {Henry Holt and Co., Inc.},
  timestamp = {2012-10-25T15:58:41.000+0200},
  title = {Vision: A Computational Investigation into the Human Representation and Processing of Visual Information},
  year = 1982
}

@article{mipmap83,
author = {Williams, Lance},
title = {Pyramidal Parametrics},
year = {1983},
issue_date = {July 1983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/964967.801126},
doi = {10.1145/964967.801126},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {1–11},
numpages = {11},
keywords = {Texture mapping, Visible surface algorithms, Modeling, Pyramidal data structures, Antialiasing, Reflectance mapping, Illumination models}
}

@inproceedings{schardong2024neural,
  title = {Neural Implicit Morphing of Face Images},
  author = {Schardong, Guilherme and Novello, Tiago and Paz, Hallison and Medvedev, Iurii and Silva, Vin{\'\i}icius da and Velho, Luiz and Gon\c{c}alves, Nuno},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2024},
  month = {June},
  pages = {7321-7330}
}

@inproceedings{sitzmann2019siren,
    author = {Sitzmann, Vincent
                and Martel, Julien N.P.
                and Bergman, Alexander W.
                and Lindell, David B.
                and Wetzstein, Gordon},
    title = {Implicit Neural Representations
                with Periodic Activation Functions},
    booktitle = {Proc. NeurIPS},
    year={2020}
}

@inproceedings{tileinteractive,
author = {Lagae, Ares and Kaplan, Craig S. and Fu, Chi-Wing and Ostromoukhov, Victor and Deussen, Oliver},
title = {Tile-Based Methods for Interactive Applications},
year = {2008},
isbn = {9781450378451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1401132.1401254},
doi = {10.1145/1401132.1401254},
abstract = {Over the last years, several techniques have been demonstrated that rely on tile-based methods. A lot of interactive applications could potentially benefit from these techniques. However, the state-of-the-art is scattered over several publications, and survey works are not available. In this class we give a detailed overview of tile-based methods in computer graphics. The class consist of four parts, which are briefly covered in the following paragraphs.Tile-Based Methods using Wang and Corner Tiles The first part of the class introduces tile-based methods in computer graphics based on Wang tiles and corner tiles. This part serves as a general introduction for the class, but also covers methods and applications based on Wang tiles and corner tiles. We introduce Wang tiles and corner tiles, and present several tiling algorithms. We discuss in detail tile-based texture mapping using graphics hardware, tile-based generation of Poisson disk distributions, and object distribution for procedural texturing. We briefly cover other applications such as sampling, non-photorealistic rendering, and geometric object distribution. The lecturer for the first part is Ares Lagae, who recently finished his PhD about tile-based methods in computer graphics [Lagae, 2007].Periodic Tilings for Computer Graphics Applications The second part of the class introduces the mathematical and algorithmic aspects of decorative tilings such as those used by M. C. Escher. It focuses on the theory of isohedral tilings, tilings that cover the plane systematically with congruent copies of a single shape. The isohedral tilings are flexible enough to support a wide variety of applications in art and design, while admitting a compact and efficient implementation. We show how to store, manipulate and render isohedral tilings, and survey some recent applications. The lecturer for the second part is Craig Kaplan, an expert on the use of computer graphics in ornamental design Kaplan [2002].Tile-Based Methods for Surface Modeling The third part of the class covers tilebased methods for surface modeling. Tiling is a practical and cost-effective method for high-quality surface modeling and rendering. Rather than intensive data acquisition and synthesis, the generalized Wang tile set presented in this part of the talk allows us to seamlessly and non-periodically tile texture data on parameterized surfaces of arbitrary topology. Once we synthesize textures on tiles, we can reuse the same tile set on different surfaces and we can also instantaneously change the surface appearance by just switching the reference tile set. Further than color textures, we also extend surface tiling to include bump maps, geometry details, the BTF's, as well as Poisson disk tiling. The lecturer for the third part is Chi-Wing Fu, who wrote several papers on this topic [Fu and Leung, 2005].Non-Periodic Tilings for Computer Graphics Applications The fourth part of the class covers an important class of non-periodic tilings and their benefits for computer graphics applications. First, the theory of Penrose tilings is presented. We show how the inherent self-similarity of Penrose tiling can be exploited in order to get efficient implementation of uniform distributions with blue-noise properties. Then, we present polyomino-based uniform distributions, and show their advantages. Finally, we explore other non-periodic tiling systems, potentially usable for computer graphics applications: dodecagonal tiling, Ammann tiling, etc. The lecturer for the fourth part is Victor Ostromoukhov who is an expert in this topic [Ostromoukhov et al., 2004; Ostromoukhov, 2007].Tile-Based Methods for Non-Photorealistic Rendering and Landscape Modeling The fifth part of the class covers applications of tile-based methods in the fields of non-photorealistic rendering and landscape modeling [Cohen et al., 2003]. Using hierarchical tile sets one is able to create point sets with infinite density still showing Poisson disk characteristics [Kopf et al., 2006]. We will demonstrate this using a set of tiles that is recursively subdivided. This is possible because the set shows self similarity. The resulting points can be used to create stipple drawings and also distributions of plants that also show Poisson disk behavior. This will be demonstrated by an application that enables real-time modeling and rendering of complex landscapes. The lecturer for the fifth part is Oliver Deussen, who has considerable experience with tile-based design.},
booktitle = {ACM SIGGRAPH 2008 Classes},
articleno = {93},
numpages = {267},
location = {Los Angeles, California},
series = {SIGGRAPH '08}
}

@inproceedings{marcellin2000overview,
  title={An overview of JPEG-2000},
  author={Marcellin, Michael W and Gormish, Michael J and Bilgin, Ali and Boliek, Martin P},
  booktitle={Proceedings DCC 2000. Data Compression Conference},
  pages={523--541},
  year={2000},
  organization={IEEE}
}


@article{mallat1989theory,
  title={A theory for multiresolution signal decomposition: the wavelet representation},
  author={Mallat, Stephane G},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={11},
  number={7},
  pages={674--693},
  year={1989},
  publisher={Ieee}
}

@article{silva2022mipplicits, 
  author = {Vinicius da Silva and Tiago Novello and Guilherme Schardong and Luiz Schirmer and Helio Lopes and Luiz Velho}, 
  title = {MIP-plicits: Level of Detail Factorization of Neural Implicits Sphere Tracing}, 
  year = {2022}, 
  month = {Jan}, 
  url = {http://arxiv.org/abs/2201.09147v1} 
}


@article{antonini1992image,
  title={Image coding using wavelet transform},
  author={Antonini, Marc and Barlaud, Michel and Mathieu, Pierre and Daubechies, Ingrid},
  journal={IEEE Transactions on image processing},
  volume={1},
  number={2},
  pages={205--220},
  year={1992}
}

@phdthesis{dupont2022a,
  edition = {},
  number = {},
  journal = {},
  pages = {},
  publisher = {University of Oxford},
  school = {University of Oxford},
  title = {Neural networks as data},
  volume = {},
  author = {Dupont, E},
  editor = {},
  year = {2022},
  series = {}
}

@misc{tamingFactory,
Author = {Tiago Novello and Diana Aldana and Luiz Velho},
Title = {Taming the Frequency Factory of Sinusoidal Networks},
Year = {2024},
Eprint = {arXiv:2407.21121},
}

@inproceedings{spectralPoster24,
author = {Paz, Hallison and Novello, Tiago and Velho, Luiz},
title = {Spectral Periodic Networks for Neural Rendering},
year = {2024},
isbn = {9798400705168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641234.3671087},
doi = {10.1145/3641234.3671087},
booktitle = {ACM SIGGRAPH 2024 Posters},
articleno = {47},
numpages = {2},
keywords = {Anti-aliasing, Fourier Series, Periodic Functions, Texture Mapping},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@article{starNeuralRendering22,
author = {Tewari, A. and Thies, J. and Mildenhall, B. and Srinivasan, P. and Tretschk, E. and Yifan, W. and Lassner, C. and Sitzmann, V. and Martin-Brualla, R. and Lombardi, S. and Simon, T. and Theobalt, C. and Nießner, M. and Barron, J. T. and Wetzstein, G. and Zollhöfer, M. and Golyanik, V.},
title = {Advances in Neural Rendering},
journal = {Computer Graphics Forum},
volume = {41},
number = {2},
pages = {703-735},
doi = {https://doi.org/10.1111/cgf.14507},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14507},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14507},
abstract = {Abstract Synthesizing photo-realistic images and videos is at the heart of computer graphics and has been the focus of decades of research. Traditionally, synthetic images of a scene are generated using rendering algorithms such as rasterization or ray tracing, which take specifically defined representations of geometry and material properties as input. Collectively, these inputs define the actual scene and what is rendered, and are referred to as the scene representation (where a scene consists of one or more objects). Example scene representations are triangle meshes with accompanied textures (e.g., created by an artist), point clouds (e.g., from a depth sensor), volumetric grids (e.g., from a CT scan), or implicit surface functions (e.g., truncated signed distance fields). The reconstruction of such a scene representation from observations using differentiable rendering losses is known as inverse graphics or inverse rendering. Neural rendering is closely related, and combines ideas from classical computer graphics and machine learning to create algorithms for synthesizing images from real-world observations. Neural rendering is a leap forward towards the goal of synthesizing photo-realistic image and video content. In recent years, we have seen immense progress in this field through hundreds of publications that show different ways to inject learnable components into the rendering pipeline. This state-of-the-art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D-consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene. In addition to methods that handle static scenes, we cover neural scene representations for modeling non-rigidly deforming objects and scene editing and composition. While most of these approaches are scene-specific, we also discuss techniques that generalize across object classes and can be used for generative tasks. In addition to reviewing these state-of-the-art methods, we provide an overview of fundamental concepts and definitions used in the current literature. We conclude with a discussion on open challenges and social implications.},
year = {2022}
}

@misc{mrnetGithub,
  author={Paz, Hallison and Perazzo, Daniel and Velho, Luiz},
  title={MR-Net Framework Code},
  year={2022},
  url={https://github.com/visgraf/mrnet},
}

@inproceedings{mallat-2gen,
author = {Froment, Jacques and Mallat, Ste\'{e}phane},
title = {Second Generation Image Coding and Wavelet Transform},
year = {1996},
isbn = {311013215X},
publisher = {Walter de Gruyter \& Co.},
address = {USA},
booktitle = {Proceedings of the First World Congress on World Congress of Nonlinear Analysts '92, Volume II},
pages = {1923–1932},
numpages = {10},
location = {Tampa, Florida, USA},
series = {WCNA '92}}


@book{pixel,
  title     = "A Biography of the Pixel",
  author    = "Alvy Ray Smith",
  year      = 2021,
  publisher = "MIT Press",
  address   = "Boston"
}

@techreport{heckbert1983texture,
  title={Texture mapping polygons in perspective},
  author={Heckbert, Paul S and others},
  year={1983},
  institution={NYIT Computer Graphics Lab}
}

@misc{KodakDataset,
  author = {Kodak},
  title = {Kodak Lossless True Color Image Suite},
  howpublished = {\url{http://r0k.us/graphics/kodak/}},
  note = {Accessed: 2023-01-30},
  year = {1999}
}

@article{quasiRegularTiling,
  author = {Yin, Zhengzheng and Jin, Yao and Fang, Zhijian and Zhang, Huaxiong and Zhou, Jiu and He, Lili and Zhang, Yun},
  year = {2024},
  month = {04},
  pages = {1-18},
  title = {Symmetrization of quasi-regular patterns with periodic tilting of regular polygons},
  volume = {10},
  journal = {Computational Visual Media},
  doi = {10.1007/s41095-023-0359-z}
}

@article{match,
author = {Shi, Liang and Li, Beichen and Ha\v{s}an, Milo\v{s} and Sunkavalli, Kalyan and Boubekeur, Tamy and Mech, Radomir and Matusik, Wojciech},
title = {Match: Differentiable Material Graphs for Procedural Material Capture},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3414685.3417781},
doi = {10.1145/3414685.3417781},
abstract = {We present MATch, a method to automatically convert photographs of material samples into production-grade procedural material models. At the core of MATch is a new library DiffMat that provides differentiable building blocks for constructing procedural materials, and automatic translation of large-scale procedural models, with hundreds to thousands of node parameters, into differentiable node graphs. Combining these translated node graphs with a rendering layer yields an end-to-end differentiable pipeline that maps node graph parameters to rendered images. This facilitates the use of gradient-based optimization to estimate the parameters such that the resulting material, when rendered, matches the target image appearance, as quantified by a style transfer loss. In addition, we propose a deep neural feature-based graph selection and parameter initialization method that efficiently scales to a large number of procedural graphs. We evaluate our method on both rendered synthetic materials and real materials captured as flash photographs. We demonstrate that MATch can reconstruct more accurate, general, and complex procedural materials compared to the state-of-the-art. Moreover, by producing a procedural output, we unlock capabilities such as constructing arbitrary-resolution material maps and parametrically editing the material appearance.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {196},
numpages = {15},
keywords = {material acquisition, procedural materials}
}

@article{mallat-mr89,
  author={Mallat, S.G.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A theory for multiresolution signal decomposition: the wavelet representation}, 
  year={1989},
  volume={11},
  number={7},
  pages={674-693},
  doi={10.1109/34.192463}
}


@article{stochastic_cook,
author = {Cook, Robert},
year = {1986},
month = {01},
pages = {51-72},
title = {Stochastic Sampling in Computer Graphics},
volume = {5},
journal = {ACM Trans. Graph.},
doi = {10.1145/7529.8927}
}

@article{alfarano-opticalflow,
title = {Estimating optical flow: A comprehensive review of the state of the art},
journal = {Computer Vision and Image Understanding},
volume = {249},
pages = {104160},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104160},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002418},
author = {Andrea Alfarano and Luca Maiano and Lorenzo Papa and Irene Amerini},
keywords = {Computer Vision, Optical flow, motion estimation},
abstract = {Optical flow estimation is a crucial task in computer vision that provides low-level motion information. Despite recent advances, real-world applications still present significant challenges. This survey provides an overview of optical flow techniques and their application. For a comprehensive review, this survey covers both classical frameworks and the latest AI-based techniques. In doing so, we highlight the limitations of current benchmarks and metrics, underscoring the need for more representative datasets and comprehensive evaluation methods. The survey also highlights the importance of integrating industry knowledge and adopting training practices optimized for deep learning-based models. By addressing these issues, future research can aid the development of robust and efficient optical flow methods that can effectively address real-world scenarios.}
}

@article{poisson_bridson,
author = {Bridson, Robert},
year = {2007},
month = {08},
pages = {},
title = {Fast Poisson disk sampling in arbitrary dimensions},
journal = {ACM SIGGRAPH},
doi = {10.1145/1278780.1278807}
}

@book{rosenfeld2013multiresolution,
  title={Multiresolution Image Processing and Analysis},
  author={Rosenfeld, A.},
  isbn={9783642515903},
  lccn={83020074},
  series={Springer Series in Information Sciences},
  url={https://books.google.com.br/books?id=ZGirCAAAQBAJ},
  year={2013},
  publisher={Springer Berlin Heidelberg}
}

@book{velho2009image,
  title={Image processing for computer graphics and vision},
  author={Velho, Luiz and Frery, Alejandro C and Gomes, Jonas},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@article{lindeberg1994scale,
  title={Scale-space theory: A basic tool for analyzing structures at different scales},
  author={Lindeberg, Tony},
  journal={Journal of applied statistics},
  volume={21},
  number={1-2},
  pages={225--270},
  year={1994},
  publisher={Taylor \& Francis}
}


@article{Moritz2017Texture,
    author = {Moritz, J. and James, Stuart and Haines, Tom S. F. and Ritschel, Tobias and Weyrich, Tim},
    title = {Texture Stationarization: Turning Photos Into Tileable Textures},
    journal = {Computer Graphics Forum (Proc. Eurographics)},
    volume = 36,
    number = 2,
    pages = {177--188},
    year = 2017,
    month = may,
    day = 23,
    publisher = {Eurographics Association},
    authorurl = {http://reality.cs.ucl.ac.uk/projects/texture/moritz17texture.html},
}

@article{novello2022understanding,
  title={Understanding Sinusoidal Neural Networks},
  author={Novello, Tiago},
  journal={arXiv preprint arXiv:2212.01833},
  year={2022}
}

@inproceedings{Rahaman2018O,
  title={On the Spectral Bias of Neural Networks},
  author={Nasim Rahaman and Aristide Baratin and Devansh Arpit and Felix Dr{\"a}xler and Min Lin and Fred A. Hamprecht and Yoshua Bengio and Aaron C. Courville},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@misc{rahaman2018spectral,
  abstract = {Neural networks are known to be a class of highly expressive functions able
to fit even random input-output mappings with $100\%$ accuracy. In this work,
we present properties of neural networks that complement this aspect of
expressivity. By using tools from Fourier analysis, we show that deep ReLU
networks are biased towards low frequency functions, meaning that they cannot
have local fluctuations without affecting their global behavior. Intuitively,
this property is in line with the observation that over-parameterized networks
find simple patterns that generalize across data samples. We also investigate
how the shape of the data manifold affects expressivity by showing evidence
that learning high frequencies gets \emph{easier} with increasing manifold
complexity, and present a theoretical understanding of this behavior. Finally,
we study the robustness of the frequency components with respect to parameter
perturbation, to develop the intuition that the parameters must be finely tuned
to express high frequency functions.},
  added-at = {2021-02-03T09:54:02.000+0100},
  author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred A. and Bengio, Yoshua and Courville, Aaron},
  biburl = {https://www.bibsonomy.org/bibtex/24297aafa6045daa9b53b66e9934d5f6d/louissf},
  description = {On the Spectral Bias of Neural Networks},
  interhash = {ed126edbcd89f7ae987f99aaf8d8133f},
  intrahash = {4297aafa6045daa9b53b66e9934d5f6d},
  keywords = {ai math relu spectral},
  note = {cite arxiv:1806.08734Comment: 23 pages},
  timestamp = {2021-02-03T09:56:10.000+0100},
  title = {On the Spectral Bias of Neural Networks},
  url = {http://arxiv.org/abs/1806.08734},
  year = 2018
}

@article{mueller2022instant,
    author = {Thomas M\"uller and Alex Evans and Christoph Schied and Alexander Keller},
    title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
    journal = {ACM Trans. Graph.},
    issue_date = {July 2022},
    volume = {41},
    number = {4},
    month = jul,
    year = {2022},
    pages = {102:1--102:15},
    articleno = {102},
    numpages = {15},
    url = {https://doi.org/10.1145/3528223.3530127},
    doi = {10.1145/3528223.3530127},
    publisher = {ACM},
    address = {New York, NY, USA}
}

@article{martel2021acorn,
  title={{ACORN}: {Adaptive} coordinate networks for neural scene representation},
  author={Julien N. P. Martel and David B. Lindell and Connor Z. Lin and Eric R. Chan and Marco Monteiro and Gordon Wetzstein},
  journal={ACM Trans. Graph. (SIGGRAPH)},
  volume={40},
  number={4},
  year={2021},
}

@article{tancik2020fourfeat,
    title={Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains},
    author={Matthew Tancik and Pratul P. Srinivasan and Ben Mildenhall and Sara Fridovich-Keil and Nithin Raghavan and Utkarsh Singhal and Ravi Ramamoorthi and Jonathan T. Barron and Ren Ng},
    journal={NeurIPS},
    year={2020}
}

@inproceedings{ntc2023,
    author = {Vaidyanathan, Karthik and Salvi, Marco and Wronski, Bartlomiej and Akenine-Möller, Tomas and Ebelin, Pontus and Lefohn, Aaron},
    title = "{Random-Access Neural Compression of Material Textures}",
    year = {2023},
    booktitle = {Proceedings of SIGGRAPH},
}

@inproceedings {pauly-2009,
booktitle = {Eurographics 2009 - State of the Art Reports},
editor = {M. Pauly and G. Greiner},
title = {{State of the Art in Example-based Texture Synthesis}},
author = {Wie, Li-Yi and Lefebvre, Sylvain and Kwatra, Vivek and Turk, Greg},
year = {2009},
publisher = {The Eurographics Association},
}

@INPROCEEDINGS{paz2022,  author={Paz, Hallison and Novello, Tiago and Silva, Vinicius and Schardong, Guilherme and Schirmer, Luiz and Chagas, Fabio and Lopes, Helio and Velho, Luiz},  booktitle={2022 35th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)},   title={Multiresolution Neural Networks for Imaging},   year={2022},  volume={1},  number={},  pages={174-179},  doi={10.1109/SIBGRAPI55357.2022.9991765}
}


@article{paz2023mr,
  title={MR-Net: Multiresolution sinusoidal neural networks},
  author={Paz, Hallison and Perazzo, Daniel and Novello, Tiago and Schardong, Guilherme and Schirmer, Luiz and da Silva, Vinicius and Yukimura, Daniel and Chagas, Fabio and Lopes, Helio and Velho, Luiz},
  journal={Computers \& Graphics},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{perez2003,
author = {P\'{e}rez, Patrick and Gangnet, Michel and Blake, Andrew},
title = {Poisson image editing},
year = {2003},
isbn = {1581137095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1201775.882269},
doi = {10.1145/1201775.882269},
abstract = {Using generic interpolation machinery based on solving Poisson equations, a variety of novel tools are introduced for seamless editing of image regions. The first set of tools permits the seamless importation of both opaque and transparent source image regions into a destination region. The second set is based on similar mathematical ideas and allows the user to modify the appearance of the image seamlessly, within a selected region. These changes can be arranged to affect the texture, the illumination, and the color of objects lying in the region, or to make tileable a rectangular selection.},
booktitle = {ACM SIGGRAPH 2003 Papers},
pages = {313–318},
numpages = {6},
keywords = {Poisson equation, guided interpolation, image gradient, interactive image editing, seamless cloning, selection editing},
location = {San Diego, California},
series = {SIGGRAPH '03}
}

@article{perlin-1985,
author = {Perlin, Ken},
title = {An Image Synthesizer},
year = {1985},
issue_date = {Jul. 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {0097-8930},
url = {https://doi.org/10.1145/325165.325247},
doi = {10.1145/325165.325247},
abstract = {We introduce the concept of a Pixel Stream Editor. This forms the basis for an interactive synthesizer for designing highly realistic Computer Generated Imagery. The designer works in an interactive Very High Level programming environment which provides a very fast concept/implement/view iteration cycle.Naturalistic visual complexity is built up by composition of non-linear functions, as opposed to the more conventional texture mapping or growth model algorithms. Powerful primitives are included for creating controlled stochastic effects. We introduce the concept of "solid texture" to the field of CGI.We have used this system to create very convincing representations of clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The algorithms created with this paradigm are generally extremely fast, highly realistic, and asynchronously parallelizable at the pixel level.},
journal = {SIGGRAPH Comput. Graph.},
month = {jul},
pages = {287–296},
numpages = {10},
keywords = {interactive, functional composition, solid texture, fire, space function, turbulence, pixel stream editor, waves, stochastic modelling, algorithm development}
}

@inproceedings{taming2017,
  title={Taming the waves: sine as activation function in deep neural networks},
  author={Giambattista Parascandolo and Heikki Huttunen and Tuomas Virtanen},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:126004626}
}


@article{thies19,
author = {J. Thies and M. Zollh\"{o}fer and M. Nie\ss{}ner},
title = {Deferred Neural Rendering: Image Synthesis Using Neural Textures},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3306346.3323035},
doi = {10.1145/3306346.3323035},
journal = {ACM Trans. Graph.},
articleno = {66},
numpages = {12},
keywords = {novel view synthesis, facial reenactment, neural rendering, neural texture}
}

@inproceedings{yuce2022structured,
  title={A structured dictionary perspective on implicit neural representations},
  author={Y{\"u}ce, Gizem and Ortiz-Jim{\'e}nez, Guillermo and Besbinar, Beril and Frossard, Pascal},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19228--19238},
  year={2022}
}

@article {rethinkngtex,
journal = {Computer Graphics Forum},
title = {{Rethinking Texture Mapping}},
author = {Yuksel, Cem and Lefebvre, Sylvain and Tarini, Marco},
year = {2019},
publisher = {The Eurographics Association and John Wiley & Sons Ltd.},
ISSN = {1467-8659},
DOI = {10.1111/cgf.13656}
}

@inproceedings{tilehard, author = {Wei, Li-Yi}, title = {Tile-Based Texture Mapping on Graphics Hardware}, year = {2004}, isbn = {3905673150}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1058129.1058138}, doi = {10.1145/1058129.1058138}, abstract = {Texture mapping has been a fundamental feature for commodity graphics hardware. However, a key challenge for texture mapping is how to store and manage large textures on graphics processors. In this paper, we present a tile-based texture mapping algorithm by which we only have to physically store a small set of texture tiles instead of a large texture. Our algorithm generates an arbitrarily large and non-periodic virtual texture map fr\`{o}m the small set of stored texture tiles. Because we only have to store a small set of tiles, it minimizes the storage requirement to a small constant, regardless of the size of the virtual texture. In addition, the tiles are generated and packed into a single texture map, so that the hardware filtering of this packed texture map corresponds directly to the filtering of the virtual texture. We implement our algorithm as a fragment program, and demonstrate performance on latest graphics processors.}, booktitle = {Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware}, pages = {55–63}, numpages = {9}, keywords = {graphics hardware, texture mapping, texture synthesis}, location = {Grenoble, France}, series = {HWWS '04} }

@misc{zhou2022tilegen,
      title={TileGen: Tileable, Controllable Material Generation and Capture}, 
      author={Xilong Zhou and Miloš Hašan and Valentin Deschaintre and Paul Guerrero and Kalyan Sunkavalli and Nima Kalantari},
      year={2022},
      eprint={2206.05649},
      archivePrefix={arXiv},
      primaryClass={cs.GR}
}

@misc{davies2021effectivenessweightencodedneuralimplicit,
      title={On the Effectiveness of Weight-Encoded Neural Implicit 3D Shapes}, 
      author={Thomas Davies and Derek Nowrouzezahrai and Alec Jacobson},
      year={2021},
      eprint={2009.09808},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2009.09808}, 
}


@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press},
  note={\url{http://www.deeplearningbook.org}},
}

@article{Talpes2020Tesla,
  title={Compute Solution for Tesla's Full Self-Driving Computer},
  author={Emil Talpes and Atchyuth Gorti and Gagandeep S. Sachdev and Debjit Das Sarma and Ganesh Venkataramanan and Peter J. Bannon and Bill McGee and Benjamin Floering and Ankit Jalote and Christopher Hsiong and Sahil Arora},
  journal={IEEE Micro},
  year={2020},
  volume={40},
  pages={25-35},
  url={https://api.semanticscholar.org/CorpusID:213096510}
}

@misc{appleNeural,
	author = {Atila Orhon and Aseem Wadhwa and Youchang Kim and Francesco Rossi and Vignesh Jagadeesh},
	title = {Deploying Transformers on the Apple Neural Engine},
	howpublished = {\url{https://machinelearning.apple.com/research/vision-transformers}},
	year = {2022},
	note = {[Accessed 21-10-2024]},
}

@misc{googleTPU,
	author = {Kaz Sato and Cliff Young},
	title = {{A}n in-depth look at {G}oogle’s first {T}ensor {P}rocessing {U}nit ({T}{P}{U}) | {G}oogle {C}loud {B}log --- cloud.google.com},
	howpublished = {\url{https://cloud.google.com/blog/products/ai-machine-learning/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu}},
	year = {2017},
	note = {[Accessed 21-10-2024]},
}

@inproceedings{xie2022neural,
  title={Neural fields in visual computing and beyond},
  author={Xie, Yiheng and Takikawa, Towaki and Saito, Shunsuke and Litany, Or and Yan, Shiqin and Khan, Numair and Tombari, Federico and Tompkin, James and Sitzmann, Vincent and Sridhar, Srinath},
  booktitle={Computer Graphics Forum},
  volume={41},
  pages={641--676},
  year={2022},
  organization={Wiley Online Library}
}

@article{czerkawski2021neural,
  title={Neural knitworks: Patched neural implicit representation networks},
  author={Czerkawski, Mikolaj and Cardona, Javier and Atkinson, Robert and Michie, Craig and Andonovic, Ivan and Clemente, Carmine and Tachtatzis, Christos},
  journal={arXiv preprint arXiv:2109.14406},
  year={2021}
}


@inproceedings{chen2021learning,
  title={Learning continuous image representation with local implicit image function},
  author={Chen, Yinbo and Liu, Sifei and Wang, Xiaolong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8628--8638},
  year={2021}
}

@inproceedings{dupont2021coin,
  title={{COIN}: {CO}mpression with Implicit Neural representations},
  author={Emilien Dupont and Adam Golinski and Milad Alizadeh and Yee Whye Teh and Arnaud Doucet},
  booktitle={Neural Compression: From Information Theory to Applications -- Workshop @ ICLR 2021},
  year={2021},
  url={https://openreview.net/forum?id=yekxhcsVi4}
}

@article{dupont2022coinpp,
  title={{COIN}++: Neural Compression Across Modalities},
  author={Emilien Dupont and Hrushikesh Loya and Milad Alizadeh and Adam Golinski and Yee Whye Teh and Arnaud Doucet},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2022},
  url={https://openreview.net/forum?id=NXB0rEM2Tq},
  note={}
}

@inproceedings{redmon2016you,
  title={You Only Look Once: Unified, Real-Time Object Detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={779--788},
  year={2016}
}

@inproceedings{he2017mask,
  title={Mask R-CNN},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  pages={2961--2969},
  year={2017}
}

@article{cao2019openpose,
  title={OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  author={Cao, Zhe and Hidalgo, Gabriel and Simon, Thomas and Wei, Shih-En and Sheikh, Yaser},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={43},
  number={6},
  pages={172--186},
  year={2019}
}

@article{chen2018deeplab,
  title={DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs},
  author={Chen, Liang-Chieh and Papandreou, Georgios and Schroff, Florian and Adam, Hartwig},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={40},
  number={4},
  pages={834--848},
  year={2018}
}

@inproceedings{long2015fully,
  title={Fully Convolutional Networks for Semantic Segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3431--3440},
  year={2015}
}

@inproceedings{guler2018densepose,
  title={DensePose: Dense Human Pose Estimation In The Wild},
  author={Guler, Raquel and Rodriguez, Esteban and Alperovich, Andrey and et al.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7297--7306},
  year={2018}
}

@inproceedings{vinyals2015show,
  title={Show and Tell: A Neural Image Caption Generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3156--3164},
  year={2015}
}

@inproceedings{eigen2014depth,
  title={Depth Map Prediction from a Single Image using a Multi-Scale Deep Network},
  author={Eigen, David and Fergus, Rob},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2366--2374},
  year={2014}
}

@inproceedings{kingma2014auto,
  title={Auto-Encoding Variational Bayes},
  author={Kingma, D. P. and Welling, M.},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2014}
}

@inproceedings{karras2017progressive,
  title={Progressive Growing of GANs for Improved Quality, Stability, and Variation},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Joonas},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@inproceedings{donahue2018adversarial,
  title={Adversarial Audio Synthesis},
  author={Donahue, Chris and McAuley, Julian and Puckette, Miller},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2018}
}

@inproceedings{vondrick2016generating,
  title={Generating Videos with Scene Dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={29},
  year={2016}
}

@inproceedings{wu2016shapenets,
  title={3D ShapeNets: A Deep Representation for Volumetric Shapes},
  author={Wu, Zhicheng and Zhang, Charles R. and Xie, L.},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1912--1920},
  year={2016}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SOFTWARES  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{substance_sampler,
    title        = {Substance 3D Sampler},
    author       = {Adobe},
    year         = {2023},
    note         ={\url{https://www.adobe.com/products/substance3d-sampler.html} [Accessed: Jan 2024]}}



